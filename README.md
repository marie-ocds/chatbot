# Doctor Dolittle RAG Chatbot

An intelligent question-answering system for "The Story of Doctor Dolittle" by Hugh Lofting, built using Retrieval-Augmented Generation (RAG) with LlamaIndex and ChromaDB.

## Overview

This chatbot implements a multi-level retrieval system that intelligently routes user queries to the most appropriate knowledge base:
- **Book-level**: For questions about overall themes, summary, and high-level analysis
- **Chapter-level**: For questions about specific chapters or chapter summaries
- **Scene-level**: For detailed questions about specific events, actions, or facts

## Features

- **Intelligent Query Routing**: Automatically determines the optimal retrieval strategy based on query type
- **Multi-Granularity Retrieval**: Three-tier indexing system (book/chapter/scene) for efficient and accurate responses
- **Optimized Performance**: Minimal similarity search overhead for single-document queries
- **Persistent Storage**: Uses ChromaDB for vector storage with automatic index persistence
- **Configurable Chunking**: Adjustable chunk sizes for scene-level retrieval

## Architecture

### Indexing System

1. **Book Index**: Contains a global summary generated by concatenating chapter summaries
2. **Chapter Index**: Stores individual chapter documents with metadata (chapter number, title)
3. **Scenes Index**: Fine-grained chunks of text for detailed factual queries

### Query Routing

The system uses an LLM-based router that:
- Analyzes the user query
- Determines the appropriate index (book/chapter/scene)
- Extracts chapter numbers if mentioned
- Routes the query to the optimal retrieval engine

### Retrieval Optimization

- Book and specific chapter queries use `similarity_top_k=1` (only one document exists)
- Scene queries use configurable `SCENE_SIMILARITY_TOP_K` for multi-document retrieval
- Metadata filtering for chapter-specific queries

## Installation

### Prerequisites

- Python 3.12+
- OpenAI API key

### Setup

1. Clone the repository:
```bash
git clone https://github.com/marie-ocds/chatbot
cd project
```

2. Create a virtual environment:
```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Create a `.env` file in the project root:
```env
OPENAI_API_KEY=your_api_key_here
```

## Configuration

All configuration parameters are centralized in `src/config.py`:

```python
# LLM Configuration
LLM_MODEL = "gpt-4o-mini-2024-07-18"

# Embedding Configuration
EMBEDDING_MODEL = "text-embedding-3-small"

# Text splitting configuration
SCENE_CHUNK_SIZE = 600
SCENE_CHUNK_OVERLAP = 80

# Retrieval configuration
SCENE_SIMILARITY_TOP_K = 3
```

## Usage

### Running the Chatbot locally

```bash
python main.py
```

The chatbot will:
1. Load or build the vector indices (first run will take longer)
2. Start an interactive Q&A session
3. Accept natural language questions about the book

Example queries:
- "What is the main theme of the book?"
- "What happens in chapter 5?"
- "Who is Polynesia?"

Type `exit` or `quit` to end the session.

### Web interface

The chatbot can also be run online as a streamlit app: https://chatbot-doc-dolittle.streamlit.app/

### Text Processing Pipeline

1. **PDF Extraction**: Extract raw text using PyMuPDF
2. **Text Cleaning**: Remove formatting artifacts, normalize whitespace
3. **Chapter Detection**: Identify chapter boundaries and titles
4. **Document Creation**: Generate structured documents with metadata
5. **Chunking**: Split chapters into scenes using sentence-aware splitting
6. **Embedding**: Generate vector embeddings using OpenAI
7. **Indexing**: Store in ChromaDB for efficient retrieval

## Acknowledgments

- Book: "The Story of Doctor Dolittle" by Hugh Lofting
- Framework: LlamaIndex
- Vector Database: ChromaDB
- LLM Provider: OpenAI